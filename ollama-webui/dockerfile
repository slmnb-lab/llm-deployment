# 使用官方镜像作为基础镜像
FROM ghcr.io/open-webui/open-webui:ollama

# 设置工作目录
WORKDIR /app/backend

# 复制检查脚本
COPY pullmodel.sh /app/backend/
RUN chmod +x /app/backend/pullmodel.sh

# 创建数据持久化的卷
# VOLUME ["/root/.ollama", "/app/backend/data"]

# 暴露端口
EXPOSE 8080

# 设置默认模型环境变量
ENV OLLAMA_HOST=0.0.0.0:11434
ENV USE_OLLAMA=true
ENV USE_CUDA=true
# 设置容器启动命令
CMD ["/app/backend/pullmodel.sh"]